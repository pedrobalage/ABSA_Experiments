{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to produce the ReLi Corpus with PALAVRAS parser dependency output\n",
    "\n",
    "Using PALAVRAS revision 10754, compiled on 2015-06-06.\n",
    "\n",
    "\n",
    "Corpus reference:\n",
    " \n",
    "          Freitas, C., Motta, E., Milidiú, R., & Cesar, J. (2012).\n",
    "          Vampiro que brilha... rá! Desafios na anotação de opinião em um corpus\n",
    "          de resenhas de livros. Proceedings do XI Encontro de Linguística de Corpus (XI ELC). São Carlos - SP.\n",
    "          http://www.linguateca.pt/Repositorio/ReLi/\n",
    "\n",
    "Parser reference:\n",
    "\n",
    "          Bick, Eckhard (2000), The Parsing System \"Palavras\" - Automatic Grammatical \n",
    "          Analysis of Portuguese in a Constraint Grammar Framework\n",
    "          Aarhus: Aarhus University Press -- dr.phil. thesis\n",
    "          http://beta.visl.sdu.dk/constraint_grammar.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from lxml.etree import XMLSyntaxError\n",
    "from subprocess import Popen, PIPE\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RELI_CORPUS = '../corpus/ReLi.xml'\n",
    "\n",
    "CORPUS_PALAVRAS = '../corpus/ReLiPalavras.xml\n",
    "\n",
    "PALAVRAS_CMD = ['/opt/palavras/por.pl', '--role']\n",
    "PALAVRAS_MALT = ['/opt/palavras/bin/visldep2malt.pl']\n",
    "PALAVRAS_EXTRA2SEM = ['/opt/palavras/bin/extra2sem']\n",
    "\n",
    "# necessary to PALAVRAS\n",
    "os.environ['PERL_UNICODE'] = 'SDA'\n",
    "\n",
    "logging.basicConfig(filename='ReLiPalavras.log', level=logging.DEBUG)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# detokenizer\n",
    "def detokenizer(sentence):\n",
    "    # punctuation to keep close to the left word: . , .. ... : ? ! ;\n",
    "    # final stop?\n",
    "    sentence = re.sub(r' (\\.|,|\\.\\.|\\.\\.\\.|:|\\?|!|;)',\n",
    "                      r'\\1', sentence, flags=re.U)\n",
    "\n",
    "    # punctuation to keep close to the both words: -se -me\n",
    "    sentence = re.sub(r'(\\w) (-) (a|as|o|os|se|me|te|vos|lhe|lha|lhes|lhas|na|nas|no|nos|la|las|lo|los)( |$)',\n",
    "                      r'\\1\\2\\3\\4', sentence, flags=re.U)\n",
    "\n",
    "    # punctuation to keep in context (x) \"x\" 'x'\n",
    "    sentence = re.sub(r'\\( (.*?) \\)', r'(\\1)', sentence, flags=re.U)\n",
    "    sentence = re.sub(r'\" (.*?) \"', r'\"\\1\"', sentence, flags=re.U)\n",
    "    sentence = re.sub(r\"' (.*?) '\", r\"'\\1'\", sentence, flags=re.U)\n",
    "\n",
    "    # correct emoticons!\n",
    "    sentence = sentence.replace(': )', ' :)')\n",
    "    sentence = sentence.replace(': (', ' :(')\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contractions = dict(\n",
    "[('ao', ('a', 'o')),\n",
    " ('aonde', ('a', 'onde')),\n",
    " ('aos', ('a', 'os')),\n",
    " ('comigo', ('com', 'mim')),\n",
    " ('conosco', ('com', 'nós')),\n",
    " ('contigo', ('com', 'ti')),\n",
    " ('convosco', ('com', 'vós')),\n",
    " ('da', ('de', 'a')),\n",
    " ('dacolá', ('de', 'acolá')),\n",
    " ('dali', ('de', 'ali')),\n",
    " ('daquela', ('de', 'aquela')),\n",
    " ('daquelas', ('de', 'aquelas')),\n",
    " ('daquele', ('de', 'aquele')),\n",
    " ('daqueles', ('de', 'aqueles')),\n",
    " ('daqui', ('de', 'aqui')),\n",
    " ('daquilo', ('de', 'aquilo')),\n",
    " ('das', ('de', 'as')),\n",
    " ('daí', ('de', 'aí')),\n",
    " ('dela', ('de', 'ela')),\n",
    " ('delas', ('de', 'elas')),\n",
    " ('dele', ('de', 'ele')),\n",
    " ('deles', ('de', 'eles')),\n",
    " ('dentre', ('de', 'entre')),\n",
    " ('dessa', ('de', 'essa')),\n",
    " ('dessas', ('de', 'essas')),\n",
    " ('desse', ('de', 'esse')),\n",
    " ('desses', ('de', 'esses')),\n",
    " ('desta', ('de', 'esta')),\n",
    " ('destas', ('de', 'estas')),\n",
    " ('deste', ('de', 'este')),\n",
    " ('destes', ('de', 'estes')),\n",
    " ('disso', ('de', 'isso')),\n",
    " ('disto', ('de', 'isto')),\n",
    " ('do', ('de', 'o')),\n",
    " ('donde', ('de', 'onde')),\n",
    " ('dos', ('de', 'os')),\n",
    " ('doutra', ('de', 'outra')),\n",
    " ('doutras', ('de', 'outras')),\n",
    " ('doutro', ('de', 'outro')),\n",
    " ('doutros', ('de', 'outros')),\n",
    " ('na', ('em', 'a')),\n",
    " ('naquela', ('em', 'aquela')),\n",
    " ('naquelas', ('em', 'aquelas')),\n",
    " ('naquele', ('em', 'aquele')),\n",
    " ('naqueles', ('em', 'aqueles')),\n",
    " ('naquilo', ('em', 'aquilo')),\n",
    " ('nas', ('em', 'as')),\n",
    " ('nela', ('em', 'ela')),\n",
    " ('nelas', ('em', 'elas')),\n",
    " ('nele', ('em', 'ele')),\n",
    " ('neles', ('em', 'eles')),\n",
    " ('nessa', ('em', 'essa')),\n",
    " ('nessas', ('em', 'essas')),\n",
    " ('nesse', ('em', 'esse')),\n",
    " ('nesses', ('em', 'esses')),\n",
    " ('nesta', ('em', 'esta')),\n",
    " ('nestas', ('em', 'estas')),\n",
    " ('neste', ('em', 'este')),\n",
    " ('nestes', ('em', 'estes')),\n",
    " ('nisso', ('em', 'isso')),\n",
    " ('no', ('em', 'o')),\n",
    " ('nos', ('em', 'os')),\n",
    " ('noutra', ('em', 'outra')),\n",
    " ('noutras', ('em', 'outras')),\n",
    " ('noutro', ('em', 'outro')),\n",
    " ('noutros', ('em', 'outros')),\n",
    " ('num', ('em', 'um')),\n",
    " ('numa', ('em', 'uma')),\n",
    " ('numas', ('em', 'umas')),\n",
    " ('nuns', ('em', 'uns')),\n",
    " ('pela', ('por', 'a')),\n",
    " ('pelas', ('por', 'as')),\n",
    " ('pelo', ('por', 'o')),\n",
    " ('pelos', ('por', 'os')),\n",
    " ('à', ('a', 'a')),\n",
    " ('àquela', ('a', 'aquela')),\n",
    " ('àquelas', ('a', 'aquelas')),\n",
    " ('àquele', ('a', 'aquele')),\n",
    " ('àqueles', ('a', 'aqueles')),\n",
    " ('àquilo', ('a', 'aquilo')),\n",
    " ('às', ('a', 'as'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map tokenization between reli tokenization and PALAVRAS tokenization\n",
    "def transfer_annotation(sentence, parsed_sentence, j):\n",
    "\n",
    "    parsed_sentence.set('place', sentence.get('place'))\n",
    "    parsed_sentence.set('polarity', sentence.get('polarity'))\n",
    "\n",
    "    sentence = sentence.getchildren()\n",
    "    # j is the align factor for sentence\n",
    "    size_j = len(sentence)\n",
    "\n",
    "    parsed_sentence = parsed_sentence.getchildren()\n",
    "    i = 0  # align factor for parsed_sentence\n",
    "    size_i = len(parsed_sentence)\n",
    "\n",
    "    # annotation from ReLi is transfered to PALAVRAS tokenization\n",
    "    aligned = False\n",
    "    while not aligned:\n",
    "\n",
    "        if i >= size_i or j >= size_j:\n",
    "            aligned = True\n",
    "            continue\n",
    "\n",
    "        word = parsed_sentence[i].get('form').lower()\n",
    "        candidate = sentence[j].get('form').lower()\n",
    "\n",
    "        # align match!\n",
    "        if word == candidate:\n",
    "            # transfer annotation from ReLi to PALAVRAS\n",
    "            parsed_sentence[i].set('obj', sentence[j].get('obj'))\n",
    "            parsed_sentence[i].set('opinion', sentence[j].get('opinion'))\n",
    "            i += 1\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        # PALAVRAS change symbom ' to `\n",
    "        # PALAVRAS change symbom ... to .\n",
    "        # PALAVRAS change symbom .. to .\n",
    "        # PALAVRAS change symbom - to --\n",
    "        # PALAVRAS remove dialog introduction symbol '-'\n",
    "        # PALAVRAS remove symbol ' from the word:\n",
    "        if (word == candidate.replace('\\'', '`') or\n",
    "                word == candidate.replace('...', '.') or\n",
    "                word == candidate.replace('..', '.') or\n",
    "                word == candidate.replace('-', '--') or\n",
    "                word == candidate.replace('-', '') or\n",
    "                word == candidate.replace('\\'', '')):\n",
    "            parsed_sentence[i].set('obj', sentence[j].get('obj'))\n",
    "            parsed_sentence[i].set('opinion', sentence[j].get('opinion'))\n",
    "            i += 1\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        # PALAVRAS changes admirá - las to admirar- las\n",
    "        if word.endswith('-') and len(word) >= 4 and word[:-3] == candidate[:-1]:\n",
    "            parsed_sentence[i].set('obj', sentence[j].get('obj'))\n",
    "            parsed_sentence[i].set('opinion', sentence[j].get('opinion'))\n",
    "            i += 1\n",
    "            j += 2\n",
    "            continue\n",
    "\n",
    "        # PALAVRAS sometimes put accents in the words\n",
    "        w1 = unicodedata.normalize('NFD', word).encode('ascii', 'ignore')\n",
    "        w2 = unicodedata.normalize('NFD', candidate).encode('ascii', 'ignore')\n",
    "        if w1 == w2:\n",
    "            parsed_sentence[i].set('obj', sentence[j].get('obj'))\n",
    "            parsed_sentence[i].set('opinion', sentence[j].get('opinion'))\n",
    "            i += 1\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        # tokens dont match due a collocation: hoje_em_dia\n",
    "        if '_' in word:\n",
    "            shift = word.count('_') + 1\n",
    "            collocation = '_'.join([w.get('form').lower()\n",
    "                                    for w in sentence[j: min(j + shift, size_j)]])\n",
    "            if word == collocation:\n",
    "                # transfer annotation from first ReLi token to PALAVRAS\n",
    "                parsed_sentence[i].set('obj', sentence[j].get('obj'))\n",
    "                parsed_sentence[i].set('opinion', sentence[j].get('opinion'))\n",
    "                i += 1\n",
    "                j += shift\n",
    "                continue\n",
    "\n",
    "        # PALAVRAS concatenated two, three or four tokens\n",
    "        if word.startswith(candidate):\n",
    "            for shift in [2, 3, 4]:\n",
    "                found = False\n",
    "                collocation = ''.join([w.get('form').lower() for w in sentence[\n",
    "                                      j: min(j + shift, size_j)]])\n",
    "                if word == collocation:\n",
    "                    # transfer annotation from first ReLi token to PALAVRAS\n",
    "                    parsed_sentence[i].set('obj', sentence[j].get('obj'))\n",
    "                    parsed_sentence[i].set(\n",
    "                        'opinion', sentence[j].get('opinion'))\n",
    "                    i += 1\n",
    "                    j += shift\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                continue\n",
    "\n",
    "        # contractions!\n",
    "        if candidate in contractions:\n",
    "            if (word == contractions[candidate][0] and\n",
    "                    i < size_i and\n",
    "                    parsed_sentence[i + 1].get('form').lower() == contractions[candidate][1]):\n",
    "                parsed_sentence[i].set('obj', sentence[j].get('obj'))\n",
    "                parsed_sentence[i].set('opinion', sentence[j].get('opinion'))\n",
    "                parsed_sentence[i + 1].set('obj', sentence[j].get('obj'))\n",
    "                parsed_sentence[\n",
    "                    i + 1].set('opinion', sentence[j].get('opinion'))\n",
    "\n",
    "                i += 2\n",
    "                j += 1\n",
    "\n",
    "        # PALAVRAS split a token in two, three or four tokens\n",
    "        if candidate.startswith(word):\n",
    "            for shift in [2, 3, 4]:\n",
    "                found = False\n",
    "                collocation = ''.join([w.get('form').lower() for w in parsed_sentence[\n",
    "                                      i: min(i + shift, size_i)]])\n",
    "                if candidate == collocation:\n",
    "                    for k in range(i, i + shift):\n",
    "                        # transfer annotation from first ReLi token to PALAVRAS\n",
    "                        parsed_sentence[k].set('obj', sentence[j].get('obj'))\n",
    "                        parsed_sentence[k].set(\n",
    "                            'opinion', sentence[j].get('opinion'))\n",
    "                    i += shift\n",
    "                    j += 1\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                continue\n",
    "\n",
    "        # Unknown match, but next candidate matches, so match annotations and\n",
    "        # continue...\n",
    "        if (j < size_j - 1 and word == sentence[j + 1].get('form').lower()):\n",
    "            parsed_sentence[i].set('obj', sentence[j + 1].get('obj'))\n",
    "            parsed_sentence[i].set('opinion', sentence[j + 1].get('opinion'))\n",
    "            i += 1\n",
    "            j += 2\n",
    "            continue\n",
    "\n",
    "        # Unknown match, but next word matches, so match annotations and\n",
    "        # continue...\n",
    "        if (i < size_i - 1 and parsed_sentence[i + 1].get('form').lower() == candidate):\n",
    "            parsed_sentence[i + 1].set('obj', sentence[j].get('obj'))\n",
    "            parsed_sentence[i + 1].set('opinion', sentence[j].get('opinion'))\n",
    "            i += 2\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        # Unknown match, but next words match, so match annotations and\n",
    "        # continue...\n",
    "        if (i < size_i - 1 and j < size_j - 1 and parsed_sentence[i + 1].get('form').lower() == sentence[j + 1].get('form').lower()):\n",
    "            parsed_sentence[i].set('obj', sentence[j].get('obj'))\n",
    "            parsed_sentence[i].set('opinion', sentence[j].get('opinion'))\n",
    "            i += 1\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        # I dont know the problem\n",
    "        logger.error('''Mismatch from PALAVRAS word \"{0}\"\n",
    "                        with ReLi word \"{1}\".\n",
    "                        Parsed Sentence: \"{2}\"\n",
    "                        ReLi sentence: \"{3}\"'''.format(\n",
    "            word,\n",
    "            candidate,\n",
    "            ' '.join([w.get('form') for w in parsed_sentence]),\n",
    "            ' '.join([w.get('form') for w in sentence])))\n",
    "\n",
    "        return -1\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "reviews = etree.parse(RELI_CORPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "xmldoc = etree.Element('reviews')\n",
    "for review in reviews.getroot():\n",
    "    count += 1\n",
    "    logger.info('Processing review {}/{}'.format(count, len(reviews.getroot())))\n",
    "    review_node = etree.SubElement(xmldoc, 'review')\n",
    "    review_node.set('id', review.get('id'))\n",
    "    review_node.set('book_title', review.get('book_title'))\n",
    "    review_node.set('score', review.get('score'))\n",
    "\n",
    "    for sentence in review:\n",
    "\n",
    "        sentence_string = ' '.join([w.get('form')\n",
    "                                    for w in sentence.getchildren()])\n",
    "        \n",
    "        # PALAVRAS has problem with a tokenized string since tokenization is part of the parser process\n",
    "        # this function tries to retrieved ReLi to untokenized form, since only the tokenized corpus is available\n",
    "        sentence_string = detokenizer(sentence_string)\n",
    "\n",
    "        # PALAVRAS parser\n",
    "        p = Popen(PALAVRAS_CMD, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "        (stdout, stderr) = p.communicate(input=sentence_string.encode('utf8'))\n",
    "\n",
    "        # the script to convert from visl format to malt format\n",
    "        p = Popen(PALAVRAS_MALT, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "        (stdout, stderr) = p.communicate(input=stdout)\n",
    "\n",
    "        # script to keep only semantic information output\n",
    "        p = Popen(PALAVRAS_EXTRA2SEM, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "        (stdout, stderr) = p.communicate(input=stdout)\n",
    "\n",
    "        output = stdout.decode('utf8')\n",
    "\n",
    "        # fix missing open <sentence> in xml\n",
    "        if output.find('<body>\\n</body>') == -1:\n",
    "            output = output.replace('<body>', '<body>\\n<sentence>')\n",
    "\n",
    "        # fix missing open <sentence> in xml between break sentences\n",
    "        output = re.sub(r'/>[\\n\\t ]+<word id=\"1\"',\n",
    "                        '/>\\n</sentence>\\n<sentence>\\n<word id=\"1\"', output, re.M)\n",
    "\n",
    "        # tags lixo\n",
    "        output = re.sub(r'<lixo .+?>', '', output, re.U)\n",
    "\n",
    "        # remove xml declaration necessary to load from string in etree\n",
    "        output = output.replace('<?xml version=\"1.0\" encoding=\"UTF-8\"?>', '')\n",
    "\n",
    "        # bug for output semantic roles in xml format\n",
    "        output = re.sub(r'form=\"(.+) <.*?\"', r'form=\"\\1\"', output, re.U)\n",
    "        output = re.sub(r'form=\"(.+) PU.*?\"', r'form=\"\\1\"', output, re.U)\n",
    "\n",
    "        # bug for output semantic roles showing  £CLE\n",
    "        output = output.replace(' £CLE', '')\n",
    "\n",
    "        # deal with semantic roles outputed in deprel. ex:\n",
    "        # head=\"0\" deprel=\"PU\" obj=\"O\"\n",
    "        output = re.sub(r'deprel=\"([^§]+?)\"', r'deprel=\"\\1\" srl=\"\"', output, re.U)\n",
    "\n",
    "        # head=\"0\" deprel=\"STA §PRED\" obj=\"O\"\n",
    "        output = re.sub(r'deprel=\"(.+) §(.+)?\"', r'deprel=\"\\1\" srl=\"\\2\"', output, re.U)\n",
    "        try:\n",
    "            parser = etree.XMLParser(remove_blank_text=True)\n",
    "            tree = etree.fromstring(output, parser)\n",
    "            index = 0\n",
    "        except XMLSyntaxError as err:\n",
    "            logger.error(err)\n",
    "            continue\n",
    "\n",
    "        for parsed_sentence in tree.xpath('/treebank/body/sentence'):\n",
    "\n",
    "            # since PALAVRAS has its own (unique!) tokenization, it is necessary to transfer the ReLi\n",
    "            # annotation to PALAVRAS parsed sentence\n",
    "            index = transfer_annotation(sentence, parsed_sentence, index)\n",
    "            if index != -1:\n",
    "\n",
    "                sent_node = etree.SubElement(review_node, 'sentence')\n",
    "                sent_node.set('place', sentence.get('place'))\n",
    "                sent_node.set('polarity', sentence.get('polarity'))\n",
    "\n",
    "                for word_node in parsed_sentence.getchildren():\n",
    "                    sent_node.append(word_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etree.ElementTree(xmldoc).write(CORPUS_PALAVRAS,encoding='utf8', xml_declaration=True, pretty_print=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
