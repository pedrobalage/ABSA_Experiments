{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to produce the ReLi Corpus in XML format with UNITEX lemmatizer and morfological features.\n",
    "   \n",
    "This format is similar to malt parser format. Corpus reference: \n",
    "\n",
    "     Freitas, C., Motta, E., Milidiú, R., & Cesar, J. (2012).\n",
    "     Vampiro que brilha... rá! Desafios na anotação de opinião em um corpus\n",
    "     de resenhas de livros. Proceedings do XI Encontro de Linguística de Corpus (XI ELC). São Carlos - SP.\n",
    "     http://www.linguateca.pt/Repositorio/ReLi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import gzip\n",
    "\n",
    "from lxml import etree\n",
    "import enchant\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used libraries require some extra steps:\n",
    "\n",
    "    pip install -U lxml\n",
    "    pip install -U enchant\n",
    "    apt install aspell-pt-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "root = '../corpus/ReLi/'\n",
    "xml_filename = '../corpus/ReLi.xml'\n",
    "spell_checker = enchant.Dict('pt_BR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoS Tags in ReLi (retrieved from corpus stats):\n",
    "\n",
    "```\n",
    "   FREQ    POSTAG       EXAMPLES\n",
    "  44954       N         livro, história, mundo, vida, leitura, livros, pessoas, personagens, forma, tempo\n",
    "  33068     PREP        de, em, a, por, com, para, como, Em, sobre, sem\n",
    "  31175       V         é, ler, ser, tem, são, foi, É, era, li, faz\n",
    "  29043      ART        o, a, um, os, uma, as, O, A, Um, Uma\n",
    "  15158       ,         ,\n",
    "  13572      ADJ        bom, primeiro, grande, melhor, primeira, humano, diferente, interessante, boa\n",
    "  11959      ADV        não, mais, muito, bem, já, Não, tão, sempre, ainda, um\n",
    "  11059     NPROP       Bella, Edward, Saramago, Orwell, Crepúsculo, de, Capitães, Partido, Pedro, Areia\n",
    "   9693       .         .\n",
    "   9296      KC         e, mas, ou, E, Mas, pois, tanto, quanto, porém, nem\n",
    "   8498    PROADJ       sua, esse, seu, essa, cada, seus, todos, minha, este, suas\n",
    "   7977    PROPESS      se, ele, ela, eu, me, você, nos, eles, Eu, o\n",
    "   4670      KS         que, quando, se, como, porque, Se, Quando, enquanto, Como, já\n",
    "   4628  PRO-KS-REL     que, qual, a, quem, o, quais, Que, as, cujo, cuja\n",
    "   4321      PCP        escrito, lido, sido, feito, escrita, visto, apaixonada, proibido, chamada, publicado\n",
    "   4282    PROSUB       isso, o, um, tudo, nada, todos, algo, que, O, outros\n",
    "   3866     VAUX        é, pode, ser, foi, vai, são, ter, acaba, poderia, tinha\n",
    "   2267       \"         \"\n",
    "   1765     PDEN        também, só, mesmo, apenas, até, Só, somente, exemplo, assim, afinal\n",
    "   1302       -         -\n",
    "   1214       !         !\n",
    "   1136    PRO-KS       que, o, quem, Quem, quanto, qual, O, tudo, quão, como\n",
    "   1076      NUM        um, três, duas, dois, uma, quatro, 15, 5, 3, 12\n",
    "    739      ...        ...\n",
    "    703       :         :\n",
    "    694       )         )\n",
    "    638       (         (\n",
    "    502       ?         ?\n",
    "    317       ;         ;\n",
    "    276  ADV-KS-REL     onde, quando, como\n",
    "    235       '         '\n",
    "    232    ADV-KS       como, onde, que, por, quando\n",
    "    175      IN         ai, né, Ah, Ok, Ora, ah, Ia, oh, ok, hein\n",
    "     37       [         [\n",
    "     20       =         =\n",
    "      8      CUR        R$, US$\n",
    "      2       O         ...., Legal\n",
    "      1       /         /\n",
    "      1       $         $\n",
    "      1      //         //\n",
    "      1      ..         ..\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unitex Dicionary can be downloaded from \n",
    "http://www.nilc.icmc.usp.br/nilc/projects/unitex-pb/web/dicionarios.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading unitex files for lemmatization and morfological features. This may take some time and memory...\n",
    "\n",
    "unitex = dict()\n",
    "unitex['all'] = dict()\n",
    "\n",
    "with gzip.open('Delaf2015v04.dic.gz') as fp:\n",
    "    for line in fp:\n",
    "        line = line.decode('utf8')\n",
    "        word, info = line.split(',')\n",
    "        lemma, info = info.split('.')\n",
    "        postag = info.split(':')[0].strip()\n",
    "        if len(info.split(':')) == 2:\n",
    "            morf = info.split(':')[1].strip()\n",
    "        else:\n",
    "            morf = ''\n",
    "        \n",
    "        # get the first pos tag in case of multiple\n",
    "        postag = postag.split('+')[0]\n",
    "        \n",
    "        # convert tag A to ADJ to keep similar with ReLi tags reported above\n",
    "        if postag == 'A':\n",
    "            postag = 'ADJ'\n",
    "        \n",
    "        if postag not in unitex:\n",
    "            unitex[postag] = dict()\n",
    "            \n",
    "        # no disambiguation, get the last value present in the dict\n",
    "        # keep the words organized by postag\n",
    "        unitex[postag][word] = (lemma, morf)\n",
    "        \n",
    "        # keep the 'all' lexicon, despite the tag\n",
    "        unitex['all'][word] = (lemma, morf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading files from root folder to build the xml. This operation may take some time...\n",
    "\n",
    "xmldoc = etree.Element('reviews')\n",
    "\n",
    "for filename in os.listdir(root):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(root, filename)\n",
    "        with codecs.open(filepath, encoding='utf8') as fp:\n",
    "            book_name = ''\n",
    "            sent_place = ''\n",
    "            word_id = 0\n",
    "            \n",
    "            for line in fp:\n",
    "                line = line.strip()\n",
    "\n",
    "                # check if line contains #Livro\n",
    "                if line.startswith('#Livro_'):\n",
    "                    if book_name != line[7:]:\n",
    "                        book_name = line[7:]\n",
    "\n",
    "                # check if line contains #Resenha\n",
    "                elif line.startswith('#Resenha_'):\n",
    "                    review_id = line[9:]\n",
    "                    review_node = etree.SubElement(xmldoc, 'review')\n",
    "                    review_node.set('id', review_id)\n",
    "                    review_node.set('book_title', book_name)\n",
    "\n",
    "                # check if line contains #nota\n",
    "                elif line.startswith('#Nota_'):\n",
    "                    score = line[6:]\n",
    "                    review_node.set('score', score)\n",
    "\n",
    "                # check if line contains #Título\n",
    "                elif line.startswith('#Título'):\n",
    "                    sent_node = etree.SubElement(review_node, 'sentence')\n",
    "                    sent_place = 'title'\n",
    "                    sent_node.set('place', sent_place)\n",
    "                    word_id = 0\n",
    "\n",
    "                # check if line contains #Corpo\n",
    "                elif line.startswith('#Corpo'):\n",
    "                    sent_node = etree.SubElement(review_node, 'sentence')\n",
    "                    sent_place = 'body'\n",
    "                    sent_node.set('place', sent_place)\n",
    "                    word_id = 0\n",
    "\n",
    "                # check if line contains 6 elements, this is the corpus data\n",
    "                elif len(line.split('\\t')) == 6:\n",
    "\n",
    "                    word, pos, obj, opinion, polarity, _ = line.split('\\t')\n",
    "                    lower_word = word.lower()\n",
    "                    \n",
    "                    # if word not in unitex try to correct the spell using a spell checker\n",
    "                    if lower_word not in unitex['all']:\n",
    "                        suggestions = spell_checker.suggest(lower_word)\n",
    "                        if len(suggestions) >= 1:\n",
    "                            suggestion = suggestions[0]\n",
    "\n",
    "                        # strip accents to compare with the original word.\n",
    "                        nfkd_form = unicodedata.normalize('NFKD', str(suggestion))\n",
    "                        suggestion = nfkd_form.encode('ASCII', 'ignore')\n",
    "                        \n",
    "                        # Only corrects if the suggestion is the word with the correct accent\n",
    "                        if suggestion == lower_word:\n",
    "                            # check original case for the word\n",
    "                            if word.istitle():\n",
    "                                word = suggestions[0].title()\n",
    "                            elif word.isuppter():\n",
    "                                word = suggestions[0].upper()\n",
    "                            else:\n",
    "                                word = suggestions[0]\n",
    "\n",
    "                    # check unitex for lemma and morfological features                    \n",
    "                    if pos in unitex and lower_word in unitex[pos]:\n",
    "                        base, morf = unitex[pos][lower_word]\n",
    "                    elif lower_word in unitex['all']:\n",
    "                        base, morf = unitex['all'][lower_word]\n",
    "                    else:\n",
    "                        base = word\n",
    "                        morf = ''\n",
    "\n",
    "\n",
    "                    # build word node\n",
    "                    word_node = etree.SubElement(sent_node, 'word')\n",
    "                    word_node.set('id', str(word_id))\n",
    "                    word_id += 1\n",
    "                    word_node.set('form', word)\n",
    "                    word_node.set('base', base)\n",
    "                    word_node.set('morf', morf)\n",
    "                    word_node.set('postag', pos)\n",
    "                    word_node.set('obj', obj)\n",
    "                    word_node.set('opinion', opinion)                    \n",
    "\n",
    "                    if polarity == '-':\n",
    "                        sent_node.set('polarity', 'negative')\n",
    "                    elif polarity == '+':\n",
    "                        sent_node.set('polarity', 'positive')\n",
    "                    else:\n",
    "                        sent_node.set('polarity', 'neutral')\n",
    "\n",
    "                elif len(line) == 0:\n",
    "                    sent_node = etree.SubElement(review_node, 'sentence')\n",
    "                    sent_node.set('place', sent_place)\n",
    "                    word_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save to xml file\n",
    "etree.ElementTree(xmldoc).write(xml_filename, encoding='utf8', xml_declaration=True, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
